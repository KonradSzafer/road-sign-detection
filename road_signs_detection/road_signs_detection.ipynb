{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "\n",
    "from data_utils import get_abs_path\n",
    "from data_utils import parse_annotations_xml, create_annotations_list\n",
    "from image_utils import get_bounding_box, create_mask, get_bb_from_mask, resize_img_and_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = get_abs_path(1)\n",
    "annotations_dir = root_dir / 'data' / 'annotations'\n",
    "images_dir = root_dir / 'data' / 'images'\n",
    "resized_images_dir = root_dir / 'data' / 'resized_images'\n",
    "resized_images_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_list = create_annotations_list(annotations_dir)\n",
    "df = pd.DataFrame(annotations_list)\n",
    "df = shuffle(df)\n",
    "df.insert(3, 'resized_img_filename', '')\n",
    "df.insert(7, 'class_label', '')\n",
    "df.insert(12, 'bounding_box', '')\n",
    "\n",
    "class_idxs = {'speedlimit': 0, 'stop': 1, 'crosswalk': 2, 'trafficlight': 3}\n",
    "class_labels = {0: 'speedlimit', 1: 'stop', 2: 'crosswalk', 3: 'trafficlight'}\n",
    "df['class_label'] = df['class'].apply(lambda i: class_idxs[i])\n",
    "\n",
    "print(df['class'].value_counts())\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 300\n",
    "img_height = 400\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    img_path = row['img_filename']\n",
    "    bounding_box = get_bounding_box(row)\n",
    "\n",
    "    resized_img, resized_bounding_box = resize_img_and_bb(img_path, bounding_box, img_width, img_height)\n",
    "\n",
    "    resized_img_filename = str(resized_images_dir) + '/' + row['name'] + '.png'\n",
    "    if os.path.isfile(resized_img_filename):\n",
    "        cv2.imwrite(resized_img_filename, resized_img)\n",
    "\n",
    "    df.at[idx, 'resized_img_filename'] = resized_img_filename\n",
    "    df.at[idx, 'bounding_box'] = np.array([ resized_bounding_box[0],\n",
    "                                            resized_bounding_box[1],\n",
    "                                            resized_bounding_box[2],\n",
    "                                            resized_bounding_box[3]])\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_with_mask(df_row):\n",
    "    img_filename = df_row['resized_img_filename']\n",
    "    img = cv2.imread(img_filename)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mask = create_mask(df_row['width'], df_row['height'], df_row['bounding_box']) # TODO flip width and height\n",
    "    plt.title(df_row['class'])\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(mask, alpha=0.6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    plot_img_with_mask(df.iloc[i].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "batch_size = 5\n",
    "\n",
    "X = df[['resized_img_filename', 'bounding_box']]\n",
    "y = df['class_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5)\n",
    "\n",
    "print('train size: %d val_size: %d test size: %d' % (len(X_train), len(X_val), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_bb(in_bb):\n",
    "    out_bb = []\n",
    "    out_bb.append(float(in_bb[0]) / 30)\n",
    "    out_bb.append(float(in_bb[1]) / 30)\n",
    "    out_bb.append(float(in_bb[2]) / 40)\n",
    "    out_bb.append(float(in_bb[3]) / 40)\n",
    "    return np.array(out_bb)\n",
    "\n",
    "\n",
    "def max_bb(in_bb):\n",
    "    out_bb = []\n",
    "    out_bb.append(float(in_bb[0]) * 30)\n",
    "    out_bb.append(float(in_bb[1]) * 30)\n",
    "    out_bb.append(float(in_bb[2]) * 40)\n",
    "    out_bb.append(float(in_bb[3]) * 40)\n",
    "    return np.array(out_bb)\n",
    "\n",
    "\n",
    "def train_transform(x, bb):\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.RandomChoice([\n",
    "            transforms.RandomInvert(),\n",
    "            transforms.GaussianBlur(kernel_size=(3,3)),\n",
    "            transforms.ColorJitter(brightness=0.5, contrast=0.3, saturation=0.4),\n",
    "            # transforms.RandomSolarize(threshold=1.0),\n",
    "            # transforms.RandomPerspective(distortion_scale=0.1)\n",
    "        ]),\n",
    "    ])\n",
    "    x = train_transforms(x)\n",
    "    return x, bb\n",
    "\n",
    "\n",
    "def normalization(x):\n",
    "    normalize = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    x = normalize(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class RoadSignsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, paths, bounding_boxes, labels, apply_train_transforms=False):\n",
    "        self.paths = paths.values\n",
    "        self.bounding_boxes = bounding_boxes.values\n",
    "        self.labels = labels.values\n",
    "        self.apply_train_transforms = apply_train_transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        bounding_box = self.bounding_boxes[idx]\n",
    "        x = Image.open(path)\n",
    "        if self.apply_train_transforms:\n",
    "            x, bounding_box = train_transform(x, bounding_box)\n",
    "        x = normalization(x)\n",
    "        bounding_box = min_bb(bounding_box)\n",
    "        return x, label, bounding_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RoadSignsDataset(X_train['resized_img_filename'], X_train['bounding_box'], y_train, apply_train_transforms=True)\n",
    "val_dataset = RoadSignsDataset(X_val['resized_img_filename'], X_val['bounding_box'], y_val)\n",
    "test_dataset = RoadSignsDataset(X_test['resized_img_filename'], X_test['bounding_box'], y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBmodel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BBmodel, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        layers = list(resnet.children())[:9]\n",
    "        self.features1 = nn.Sequential(*layers[:6])\n",
    "        self.features2 = nn.Sequential(*layers[6:])\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 4),\n",
    "            nn.Dropout())\n",
    "\n",
    "        self.bb = nn.Sequential(\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 4),\n",
    "            nn.Dropout())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features1(x)\n",
    "        x = self.features2(x)\n",
    "        x = F.relu(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        return self.classifier(x), self.bb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(pred_label, pred_bb, label, bb, classification_factor, bounding_box_factor):\n",
    "\n",
    "    classification_loss = F.cross_entropy(  pred_label, label,\n",
    "                                            weight=torch.Tensor([1.0, 3.0, 3.0, 3.0]).cuda(),\n",
    "                                            reduction='mean')\n",
    "\n",
    "    bounding_box_loss = F.l1_loss(  pred_bb, bb,\n",
    "                                    reduction='mean')\n",
    "\n",
    "    loss = classification_factor * classification_loss\n",
    "    loss += bounding_box_factor * bounding_box_loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "def IOU_metrics(bb_a, bb_b):\n",
    "    xA = max(bb_a[0], bb_b[0])\n",
    "    yA = max(bb_a[2], bb_b[2])\n",
    "    xB = min(bb_a[1], bb_b[1])\n",
    "    yB = min(bb_a[3], bb_b[3])\n",
    "\n",
    "    widthA = bb_a[1] - bb_a[0]\n",
    "    heightA = bb_a[3] - bb_a[2]\n",
    "    widthB = bb_b[1] - bb_b[0]\n",
    "    heightB = bb_b[3] - bb_b[2]\n",
    "    box_a_area = (widthA + 1) * (heightA + 1)\n",
    "    box_b_area = (widthB + 1) * (heightB + 1)\n",
    "\n",
    "    area_of_intersection = (xB - xA + 1) * (yB - yA + 1)\n",
    "    area_of_union = float(box_a_area + box_b_area - area_of_intersection)\n",
    "    iou = area_of_intersection / area_of_union\n",
    "    return iou\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, classification_factor, bounding_box_factor, train_model=True):\n",
    "    total_loss = 0\n",
    "    total_iou = 0\n",
    "    samples_count = 0\n",
    "    true_count = 0\n",
    "    for x, label, bb in dataloader:\n",
    "        # predictions\n",
    "        x = x.cuda().float()\n",
    "        label = label.cuda()\n",
    "        bb = bb.cuda().float()\n",
    "        pred_label, pred_bb = model(x)\n",
    "        # losses\n",
    "        loss = loss_function(pred_label, pred_bb, label, bb, classification_factor, bounding_box_factor)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # classification accuracy\n",
    "        _, pred_label = torch.max(pred_label, 1)\n",
    "        true_count += pred_label.eq(label).sum().item()\n",
    "        # object localiozation accuracy\n",
    "        for i in range(len(bb)):\n",
    "            bb_a = bb[i]\n",
    "            bb_b = pred_bb[i]\n",
    "            iou = IOU_metrics(bb_a, bb_b)\n",
    "            total_iou += iou.cuda().item()\n",
    "        # epoch loss\n",
    "        total_loss += loss\n",
    "        batch_size = label.shape[0]\n",
    "        samples_count += batch_size\n",
    "\n",
    "    total_loss = total_loss / samples_count\n",
    "    classification_accuracy = true_count / samples_count\n",
    "    mean_iou = total_iou / samples_count\n",
    "    return total_loss, classification_accuracy, mean_iou\n",
    "\n",
    "\n",
    "def train(model, optimizer, train_dataloader, val_dataloader, epochs, classification_factor=1.0, bounding_box_factor=1.0) -> None:\n",
    "    for i in range(epochs):\n",
    "        # train\n",
    "        model.eval()\n",
    "        # model.train()\n",
    "        train_loss, train_accuracy, train_iou = evaluate(model, train_dataloader, classification_factor, bounding_box_factor)\n",
    "\n",
    "        # validate\n",
    "        model.eval()\n",
    "        val_loss, val_accuracy, val_iou = evaluate(model, val_dataloader, classification_factor, bounding_box_factor)\n",
    "\n",
    "        print('Epoch: %d/%d' % (i+1, epochs))\n",
    "        print('train loss: %.3f train acc: %.3f train iou %.03f val loss: %.3f val acc: %.3f val iou %.3f' % (train_loss, train_accuracy, train_iou, val_loss, val_accuracy, val_iou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classification(model, dataset):\n",
    "    labels = []\n",
    "    preds = []\n",
    "    true_count = 0\n",
    "    total_iou = 0\n",
    "    total_count = len(dataset)\n",
    "    for i in range(total_count):\n",
    "        x, label, bounding_box = dataset[i]\n",
    "        xx = torch.FloatTensor(x[None,])\n",
    "\n",
    "        model.eval()\n",
    "        pred_label, pred_bb = model(xx.cuda())\n",
    "\n",
    "        _, pred = torch.max(pred_label, 1)\n",
    "        pred_idx = pred[0].item()\n",
    "        if pred_idx == label:\n",
    "            true_count += 1\n",
    "\n",
    "        pred_bb = pred_bb.tolist()[0]\n",
    "        iou = IOU_metrics(bounding_box, pred_bb)\n",
    "        total_iou += iou\n",
    "\n",
    "        labels.append(label)\n",
    "        preds.append(pred_idx)\n",
    "\n",
    "    test_accuracy = true_count / total_count\n",
    "    test_mean_iou = total_iou / total_count\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title('Test accuracy: %.3f, mean IOU %.3f' % (test_accuracy, test_mean_iou))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_bounding_box(model, test_dataset):\n",
    "    for i in range(len(test_dataset)):\n",
    "        x, label, bounding_box = test_dataset[i]\n",
    "        x = torch.FloatTensor(x[None,])\n",
    "\n",
    "        model.eval()\n",
    "        pred_label, pred_bb = model(x.cuda())\n",
    "        _, pred_label = torch.max(pred_label, 1)\n",
    "\n",
    "        bounding_box = list(bounding_box)\n",
    "        pred_bb = pred_bb.int().tolist()[0]\n",
    "        iou = IOU_metrics(bounding_box, pred_bb)\n",
    "\n",
    "        if i < 40:\n",
    "            bounding_box = max_bb(bounding_box)\n",
    "            pred_bb = max_bb(pred_bb)\n",
    "            plt.title('True: %s Pred: %s \\nIOU: %.3f' % (class_labels[label], class_labels[pred_label.item()], iou))\n",
    "            # print('true box:', bounding_box)\n",
    "            # print('pred box:', pred_bb)\n",
    "            # image\n",
    "            x = torch.swapaxes(x[0], 0, 2)\n",
    "            x = torch.swapaxes(x, 0, 1)\n",
    "            plt.imshow(x)\n",
    "            # true mask\n",
    "            img = create_mask(400, 300, bounding_box)\n",
    "            plt.imshow(img[:,:,0], alpha=0.4)\n",
    "            # pred mask\n",
    "            img = create_mask(400, 300, pred_bb, r=0, g=255)\n",
    "            plt.imshow(img[:,:,1], alpha=0.4)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BBmodel().cuda()\n",
    "model.eval()\n",
    "print('Model parameters:', sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.9)\n",
    "train(model, optimizer, train_dataloader, val_dataloader, 10, classification_factor=0.3, bounding_box_factor=1.5) #25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classification(model, test_dataset)\n",
    "test_bounding_box(model, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96f4e9d9cee1c8ae9bd48da6330bc514dc698139108d0f8b9d3c1022482ebcc2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('wdsi_semester_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
