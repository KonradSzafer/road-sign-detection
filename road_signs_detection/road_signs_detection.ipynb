{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import get_abs_path\n",
    "from data_utils import parse_annotations_xml, create_annotations_list\n",
    "from image_utils import get_bounding_box, create_mask, resize_img_and_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = get_abs_path(1)\n",
    "annotations_dir = root_dir / 'data' / 'annotations'\n",
    "images_dir = root_dir / 'data' / 'images'\n",
    "resized_images_dir = root_dir / 'data' / 'resized_images'\n",
    "resized_images_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_list = create_annotations_list(annotations_dir)\n",
    "df = pd.DataFrame(annotations_list)\n",
    "df = shuffle(df)\n",
    "df.insert(3, 'resized_img_filename', '')\n",
    "df.insert(7, 'class_label', '')\n",
    "df.insert(12, 'bounding_box', '')\n",
    "\n",
    "class_idx = {'speedlimit': 0, 'stop': 1, 'crosswalk': 2, 'trafficlight': 3}\n",
    "df['class_label'] = df['class'].apply(lambda i: class_idx[i])\n",
    "\n",
    "print(df['class'].value_counts())\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 300\n",
    "img_height = 400\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    img_path = row['img_filename']\n",
    "    bounding_box = get_bounding_box(row)\n",
    "\n",
    "    resized_img, resized_bounding_box = resize_img_and_bb(img_path, bounding_box, img_width, img_height)\n",
    "\n",
    "    resized_img_filename = str(resized_images_dir) + '/' + row['name'] + '.png'\n",
    "    if os.path.isfile(resized_img_filename):\n",
    "        cv2.imwrite(resized_img_filename, resized_img)\n",
    "\n",
    "    df.at[idx, 'resized_img_filename'] = resized_img_filename\n",
    "    df.at[idx, 'bounding_box'] = np.array([ resized_bounding_box[0],\n",
    "                                            resized_bounding_box[1],\n",
    "                                            resized_bounding_box[2],\n",
    "                                            resized_bounding_box[3]])\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_with_mask(df_row):\n",
    "    img_filename = df_row['resized_img_filename']\n",
    "    img = cv2.imread(img_filename)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mask = create_mask( df_row['width'], df_row['height'], df_row['bounding_box'])\n",
    "    plt.title(df_row['class'])\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(mask, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    plot_img_with_mask(df.iloc[i].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "batch_size = 4\n",
    "\n",
    "X = df[['resized_img_filename', 'bounding_box']]\n",
    "y = df['class_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5)\n",
    "\n",
    "print('train size:', len(X_train))\n",
    "print('val_size:', len(X_val))\n",
    "print('test size:', len(X_test))\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadSignsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, paths, bounding_boxes, labels, transforms):\n",
    "        self.paths = paths.values\n",
    "        self.bounding_boxes = bounding_boxes.values\n",
    "        self.labels = labels.values\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        x = cv2.imread(path).astype(np.float32)\n",
    "        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB) / 255\n",
    "        x = self.transforms(x)\n",
    "        label = self.labels[idx]\n",
    "        bounding_box = self.bounding_boxes[idx]\n",
    "        return x, label, bounding_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RoadSignsDataset(X_train['resized_img_filename'], X_train['bounding_box'], y_train, transforms=data_transform)\n",
    "val_dataset = RoadSignsDataset(X_val['resized_img_filename'], X_val['bounding_box'], y_val, transforms=data_transform)\n",
    "test_dataset = RoadSignsDataset(X_test['resized_img_filename'], X_test['bounding_box'], y_test, transforms=data_transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "# test_dataloader = DataLoader(test_dataset,  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBmodel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BBmodel, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        layers = list(resnet.children())[:8]\n",
    "        self.features1 = nn.Sequential(*layers[:6])\n",
    "        self.features2 = nn.Sequential(*layers[6:])\n",
    "        self.classifier = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n",
    "        self.bb = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features1(x)\n",
    "        x = self.features2(x)\n",
    "        x = F.relu(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        return self.classifier(x), self.bb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossFunction(pred_label, pred_bb, label, bb, classification_factor=1.0, bounding_box_factor=5e-3):\n",
    "\n",
    "    classification_loss = F.cross_entropy(pred_label, label,\n",
    "                                        weight=torch.Tensor([0.3, 1.0, 1.0, 1.0]).cuda(),\n",
    "                                        reduction='mean')\n",
    "\n",
    "    bounding_box_loss = F.l1_loss(pred_bb, bb,\n",
    "                                reduction='mean')\n",
    "\n",
    "    loss = classification_factor * classification_loss\n",
    "    loss += bounding_box_factor * bounding_box_loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    total_loss = 0\n",
    "    samples_count = 0\n",
    "    true_count = 0\n",
    "    for x, label, bb in dataloader:\n",
    "        # predictions\n",
    "        x = x.cuda().float()\n",
    "        label = label.cuda()\n",
    "        bb = bb.cuda().float()\n",
    "        pred_label, pred_bb = model(x)\n",
    "        # losses\n",
    "        loss = lossFunction(pred_label, pred_bb, label, bb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # accuracy\n",
    "        _, pred_label = torch.max(pred_label, 1)\n",
    "        true_count += pred_label.eq(label).sum().item()\n",
    "        # epoch loss\n",
    "        total_loss += loss\n",
    "        batch_size = label.shape[0]\n",
    "        samples_count += batch_size\n",
    "\n",
    "    total_loss = total_loss / samples_count\n",
    "    classification_accuracy = true_count / samples_count\n",
    "    return total_loss, classification_accuracy\n",
    "\n",
    "\n",
    "def train(model, optimizer, train_dataloader, val_dataloader, epochs) -> None:\n",
    "    for i in range(epochs):\n",
    "\n",
    "        # train\n",
    "        model.eval()\n",
    "        # model.train()\n",
    "        train_loss, train_accuracy = evaluate(model, train_dataloader)\n",
    "\n",
    "        # validate\n",
    "        # model.eval()\n",
    "        model.train()\n",
    "        val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "        print('Epoch: %d/%d' % (i+1, epochs))\n",
    "        print('train loss: %.3f train acc: %.3f val loss: %.3f val acc: %.3f' % (train_loss, train_accuracy, val_loss, val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BBmodel().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.001)\n",
    "train(model, optimizer, train_dataloader, val_dataloader, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.SGD(parameters, lr=0.001, momentum=0.9)\n",
    "train(model, optimizer, train_dataloader, val_dataloader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image view with bb\n",
    "x, label, bounding_box = test_dataset[1]\n",
    "\n",
    "xx = torch.FloatTensor(x[None,])\n",
    "xx.shape\n",
    "\n",
    "model.eval()\n",
    "out_class, out_bb = model(xx.cuda())\n",
    "print(out_class, out_bb, label, bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "preds = []\n",
    "for i in range(len(test_dataset)):\n",
    "    x, label, bounding_box = test_dataset[i]\n",
    "    xx = torch.FloatTensor(x[None,])\n",
    "\n",
    "    model.eval()\n",
    "    out_class, out_bb = model(xx.cuda())\n",
    "\n",
    "    _, pred = torch.max(out_class, 1)\n",
    "    pred_idx = pred[0].item()\n",
    "    labels.append(label)\n",
    "    preds.append(pred_idx)\n",
    "\n",
    "cm = confusion_matrix(labels, preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96f4e9d9cee1c8ae9bd48da6330bc514dc698139108d0f8b9d3c1022482ebcc2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('wdsi_semester_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
